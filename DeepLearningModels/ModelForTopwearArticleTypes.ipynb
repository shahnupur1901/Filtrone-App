{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ModelForTopwearArticleType.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO1XqgrNx6GnQxkoJXTVV6A",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahnupur1901/Filtrone-App/blob/master/DeepLearningModels/ModelForTopwearArticleTypes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7TBfl4X2LWJ"
      },
      "source": [
        "! pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets download paramaggarwal/fashion-product-images-small\n",
        "! unzip /content/fashion-product-images-small.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEjDgjNJ32Io",
        "outputId": "8415992c-b891-41dd-962e-919140652a21"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "path = \"/content/myntradataset\"\n",
        "csv_path = \"/content/myntradataset/styles.csv\"\n",
        "img_path = \"/content/myntradataset/images\"\n",
        "df = pd.read_csv(csv_path, error_bad_lines=False, warn_bad_lines=False)\n",
        "\n",
        "df = df[df['baseColour'].notna()]\n",
        "df['id'] = df['id'].apply(lambda x: str(x)+'.jpg')\n",
        "df = df[df['id'].isin(os.listdir(img_path))]\n",
        "df = df.reset_index(drop=True)\n",
        "df = df.groupby(['articleType']).filter(lambda x: len(x) >= 20)\n",
        "print('DF shape:', df.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DF shape: (44005, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwvpMgkc-2Zj",
        "outputId": "208966bd-1076-47b0-f8ba-d3f70643c2a6"
      },
      "source": [
        "a = df['articleType'].unique()\n",
        "print(a)\n",
        "new_df = df[(df['articleType'] == \"Shirts\") | (df['articleType'] == \"Sweatshirts\") | (df['articleType'] == \"Tshirts\") | (df['articleType'] == \"Tops\") | (df['articleType'] == \"Shirts\") | (df['articleType'] == \"Dresses\") | (df['articleType'] == \"Kurtis\") | (df['articleType'] == \"Sweaters\") ]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Shirts' 'Jeans' 'Watches' 'Track Pants' 'Tshirts' 'Socks' 'Casual Shoes'\n",
            " 'Belts' 'Flip Flops' 'Handbags' 'Tops' 'Bra' 'Sandals' 'Shoe Accessories'\n",
            " 'Sweatshirts' 'Deodorant' 'Formal Shoes' 'Bracelet' 'Lipstick' 'Flats'\n",
            " 'Kurtas' 'Sports Shoes' 'Shorts' 'Briefs' 'Sarees'\n",
            " 'Perfume and Body Mist' 'Heels' 'Sunglasses' 'Innerwear Vests' 'Pendant'\n",
            " 'Nail Polish' 'Laptop Bag' 'Scarves' 'Dresses' 'Night suits' 'Skirts'\n",
            " 'Wallets' 'Ring' 'Kurta Sets' 'Clutches' 'Backpacks' 'Caps' 'Trousers'\n",
            " 'Earrings' 'Camisoles' 'Boxers' 'Jewellery Set' 'Dupatta' 'Capris'\n",
            " 'Lip Gloss' 'Bath Robe' 'Mufflers' 'Tunics' 'Jackets' 'Trunk'\n",
            " 'Lounge Pants' 'Face Wash and Cleanser' 'Necklace and Chains'\n",
            " 'Duffel Bag' 'Sports Sandals' 'Foundation and Primer' 'Sweaters'\n",
            " 'Free Gifts' 'Tracksuits' 'Fragrance Gift Set' 'Bangle' 'Nightdress'\n",
            " 'Ties' 'Leggings' 'Highlighter and Blush' 'Kurtis' 'Mobile Pouch'\n",
            " 'Messenger Bag' 'Face Moisturisers' 'Compact' 'Accessory Gift Set'\n",
            " 'Kajal and Eyeliner' 'Suspenders' 'Lip Liner' 'Patiala' 'Stockings'\n",
            " 'Eyeshadow' 'Churidar' 'Lounge Shorts' 'Gloves' 'Stoles' 'Salwar'\n",
            " 'Cufflinks' 'Jeggings' 'Sunscreen']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VE87_5OPAUcI",
        "outputId": "ba374292-9c79-42ad-f283-27ff01e6f34e"
      },
      "source": [
        "new_df.shape[0]\n",
        "new_df.groupby(['articleType']).size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "articleType\n",
              "Dresses         464\n",
              "Kurtis          234\n",
              "Shirts         3215\n",
              "Sweaters        277\n",
              "Sweatshirts     285\n",
              "Tops           1762\n",
              "Tshirts        7066\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJF6JWEh6vwo"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, test_df = train_test_split(new_df,test_size = 0.1, random_state=42)\n",
        "train_df, validation_df = train_test_split(new_df,test_size = 0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHW5NVQh4BE9",
        "outputId": "4c3b2fa9-8d37-46b4-82b7-e7f9323d9dc0"
      },
      "source": [
        "df.head()\n",
        "df.sample(frac=1,axis=1)\n",
        "batch_size = 16\n",
        "\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_image_generator = ImageDataGenerator(\n",
        "    rescale= 1./255,\n",
        "    shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True\n",
        "    #validation_split=0.2\n",
        ")\n",
        "validation_image_generator = ImageDataGenerator(\n",
        "    rescale= 1./255,\n",
        "    #validation_split=0.2\n",
        ")\n",
        "\n",
        "training_generator = train_image_generator.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    directory=img_path,\n",
        "    x_col=\"id\",\n",
        "    y_col=\"articleType\",\n",
        "    target_size=(96,96),\n",
        "    batch_size=batch_size,\n",
        "    #subset=\"training\"\n",
        ")\n",
        "\n",
        "validation_generator = validation_image_generator.flow_from_dataframe(\n",
        "    dataframe=validation_df,\n",
        "    directory=img_path,\n",
        "    x_col=\"id\",\n",
        "    y_col=\"articleType\",\n",
        "    target_size=(96,96),\n",
        "    batch_size=batch_size,\n",
        "    #subset=\"validation\"\n",
        ")\n",
        "test_generator = validation_image_generator.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    directory=img_path,\n",
        "    x_col=\"id\",\n",
        "    y_col=\"articleType\",\n",
        "    target_size=(96,96),\n",
        "    batch_size=batch_size,\n",
        "    #subset=\"validation\"\n",
        ")\n",
        "\n",
        "classes = len(training_generator.class_indices)\n",
        "print(training_generator.class_indices)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10642 validated image filenames belonging to 7 classes.\n",
            "Found 2661 validated image filenames belonging to 7 classes.\n",
            "Found 1331 validated image filenames belonging to 7 classes.\n",
            "{'Dresses': 0, 'Kurtis': 1, 'Shirts': 2, 'Sweaters': 3, 'Sweatshirts': 4, 'Tops': 5, 'Tshirts': 6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pE8P6L8F8sj0",
        "outputId": "b2573b77-ff17-41d8-e783-de3530f9dd11"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization,Dropout\n",
        "from keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32,(3,3), activation = 'relu', input_shape = (96,96,3)))\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "model.add(Conv2D(32,(3,3), activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32,(3,3), activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(classes, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), loss=tf.keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
        "model.summary()\n",
        "batch_size = 64\n",
        "total_train = train_df.shape[0]\n",
        "total_validation = validation_df.shape[0]\n",
        "vgg_classifier = model.fit(training_generator,\n",
        "steps_per_epoch=(total_train//batch_size),\n",
        "epochs = 20,\n",
        "validation_data=validation_generator,\n",
        "validation_steps=(total_validation//batch_size),\n",
        "batch_size = batch_size,\n",
        "verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 94, 94, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 47, 47, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 45, 45, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 22, 22, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 22, 22, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 20, 20, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 10, 10, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 10, 10, 32)        128       \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 3200)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               819456    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 7)                 1799      \n",
            "=================================================================\n",
            "Total params: 840,903\n",
            "Trainable params: 840,775\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "166/166 [==============================] - 38s 223ms/step - loss: 1.1660 - accuracy: 0.5859 - val_loss: 1.2872 - val_accuracy: 0.6143\n",
            "Epoch 2/20\n",
            "166/166 [==============================] - 37s 224ms/step - loss: 0.8306 - accuracy: 0.7007 - val_loss: 1.1073 - val_accuracy: 0.5793\n",
            "Epoch 3/20\n",
            "166/166 [==============================] - 37s 222ms/step - loss: 0.7520 - accuracy: 0.7300 - val_loss: 0.6618 - val_accuracy: 0.7637\n",
            "Epoch 4/20\n",
            "166/166 [==============================] - 37s 223ms/step - loss: 0.6738 - accuracy: 0.7585 - val_loss: 0.6374 - val_accuracy: 0.7561\n",
            "Epoch 5/20\n",
            "166/166 [==============================] - 37s 220ms/step - loss: 0.6818 - accuracy: 0.7534 - val_loss: 0.7207 - val_accuracy: 0.7546\n",
            "Epoch 6/20\n",
            "166/166 [==============================] - 38s 227ms/step - loss: 0.6564 - accuracy: 0.7624 - val_loss: 0.6970 - val_accuracy: 0.7470\n",
            "Epoch 7/20\n",
            "166/166 [==============================] - 37s 223ms/step - loss: 0.6244 - accuracy: 0.7707 - val_loss: 0.5605 - val_accuracy: 0.7881\n",
            "Epoch 8/20\n",
            "166/166 [==============================] - 37s 223ms/step - loss: 0.5569 - accuracy: 0.8005 - val_loss: 0.5302 - val_accuracy: 0.8003\n",
            "Epoch 9/20\n",
            "166/166 [==============================] - 38s 226ms/step - loss: 0.6157 - accuracy: 0.7688 - val_loss: 0.5865 - val_accuracy: 0.7683\n",
            "Epoch 10/20\n",
            "166/166 [==============================] - 38s 229ms/step - loss: 0.5429 - accuracy: 0.7910 - val_loss: 0.5337 - val_accuracy: 0.8049\n",
            "Epoch 11/20\n",
            "166/166 [==============================] - 37s 226ms/step - loss: 0.5380 - accuracy: 0.8042 - val_loss: 0.6828 - val_accuracy: 0.7561\n",
            "Epoch 12/20\n",
            "166/166 [==============================] - 37s 222ms/step - loss: 0.5041 - accuracy: 0.8102 - val_loss: 0.5366 - val_accuracy: 0.8079\n",
            "Epoch 13/20\n",
            "166/166 [==============================] - 37s 225ms/step - loss: 0.5170 - accuracy: 0.8117 - val_loss: 0.4580 - val_accuracy: 0.8323\n",
            "Epoch 14/20\n",
            "166/166 [==============================] - 38s 228ms/step - loss: 0.4934 - accuracy: 0.8208 - val_loss: 0.8956 - val_accuracy: 0.6966\n",
            "Epoch 15/20\n",
            "166/166 [==============================] - 37s 225ms/step - loss: 0.4453 - accuracy: 0.8441 - val_loss: 0.5538 - val_accuracy: 0.8003\n",
            "Epoch 16/20\n",
            "166/166 [==============================] - 37s 225ms/step - loss: 0.4595 - accuracy: 0.8272 - val_loss: 0.4264 - val_accuracy: 0.8476\n",
            "Epoch 17/20\n",
            "166/166 [==============================] - 37s 224ms/step - loss: 0.4822 - accuracy: 0.8183 - val_loss: 0.4214 - val_accuracy: 0.8460\n",
            "Epoch 18/20\n",
            "166/166 [==============================] - 37s 223ms/step - loss: 0.4779 - accuracy: 0.8157 - val_loss: 0.4135 - val_accuracy: 0.8323\n",
            "Epoch 19/20\n",
            "166/166 [==============================] - 37s 220ms/step - loss: 0.4402 - accuracy: 0.8357 - val_loss: 0.4176 - val_accuracy: 0.8491\n",
            "Epoch 20/20\n",
            "166/166 [==============================] - 37s 223ms/step - loss: 0.4161 - accuracy: 0.8358 - val_loss: 0.4689 - val_accuracy: 0.8384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62jA0qKd8wY0",
        "outputId": "c5918206-fdbe-4a3f-edf5-17faf21a7279"
      },
      "source": [
        "model.save('modelForTopArticleType85.h5')\n",
        "result = model.evaluate(test_generator,batch_size=32)\n",
        "print(\"test_loss, test accuracy\",result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "84/84 [==============================] - 5s 55ms/step - loss: 0.4479 - accuracy: 0.8370\n",
            "test_loss, test accuracy [0.4479343593120575, 0.8369646668434143]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W41d2AtV44Z7"
      },
      "source": [
        "import json\n",
        "with open('modelfortopweararticletype.json', 'w') as fp:\n",
        "    json.dump(training_generator.class_indices, fp)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}