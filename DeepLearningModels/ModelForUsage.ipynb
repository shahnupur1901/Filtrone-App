{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ModelForUsage.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMtpjpegg/HaD/mxB550MD2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahnupur1901/Filtrone-App/blob/master/DeepLearningModels/ModelForUsage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5g9sMJjvo_6"
      },
      "source": [
        "! pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets download paramaggarwal/fashion-product-images-small\n",
        "! unzip /content/fashion-product-images-small.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_nmnVk7wBP6",
        "outputId": "02f8153e-63a6-4723-bcc8-dda48465a7fa"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "path = \"/content/myntradataset\"\n",
        "csv_path = \"/content/myntradataset/styles.csv\"\n",
        "img_path = \"/content/myntradataset/images\"\n",
        "df = pd.read_csv(csv_path, error_bad_lines=False, warn_bad_lines=False,dtype=str)\n",
        "\n",
        "df = df[df['baseColour'].notna()]\n",
        "df['id'] = df['id'].apply(lambda x: str(x)+'.jpg')\n",
        "df = df[df['id'].isin(os.listdir(img_path))]\n",
        "df = df.reset_index(drop=True)\n",
        "df = df.groupby(['usage']).filter(lambda x: len(x) >= 30)\n",
        "print('DF shape:', df.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DF shape: (44039, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HUB9NMVwHlr",
        "outputId": "a2dc9079-0f6c-402e-a64a-5ceee1e8d244"
      },
      "source": [
        "df.head()\n",
        "df['usage'] = df['usage'].astype('string')\n",
        "print(df.groupby(['usage']).size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "usage\n",
            "Casual          34318\n",
            "Ethnic           3208\n",
            "Formal           2345\n",
            "Party              29\n",
            "Smart Casual       67\n",
            "Sports           3998\n",
            "Travel             26\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iiArD7w1NXH"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, test_df = train_test_split(df,test_size = 0.1, random_state=42)\n",
        "train_df, validation_df = train_test_split(df,test_size = 0.2, random_state=57)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiSUqjE3c__8",
        "outputId": "59532047-2c59-4fb1-871e-e939e5f69dae"
      },
      "source": [
        "print(df.dtypes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "id                    object\n",
            "gender                object\n",
            "masterCategory        object\n",
            "subCategory           object\n",
            "articleType           object\n",
            "baseColour            object\n",
            "season                object\n",
            "year                  object\n",
            "use                   string\n",
            "productDisplayName    object\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKfeRiztwNgP",
        "outputId": "e1a967f3-34fa-4683-f1f3-d406b2aef6f3"
      },
      "source": [
        "df.head()\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_image_generator = ImageDataGenerator(\n",
        "    rescale= 1./255,\n",
        "    shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True\n",
        "    #validation_split=0.2\n",
        ")\n",
        "validation_image_generator = ImageDataGenerator(\n",
        "    rescale= 1./255,\n",
        "    #validation_split=0.2\n",
        ")\n",
        "\n",
        "training_generator = train_image_generator.flow_from_dataframe(\n",
        "   \n",
        "    dataframe=train_df,\n",
        "    directory=img_path,\n",
        "    x_col=\"id\",\n",
        "    y_col=\"usage\",\n",
        "    target_size=(96,96),\n",
        "    batch_size=batch_size\n",
        "  \n",
        ")\n",
        "\n",
        "validation_generator = validation_image_generator.flow_from_dataframe(\n",
        "    dataframe=validation_df,\n",
        "    directory=img_path,\n",
        "    x_col=\"id\",\n",
        "    y_col=\"usage\",\n",
        "    target_size=(96,96),\n",
        "    batch_size=batch_size,\n",
        "    \n",
        ")\n",
        "test_generator = validation_image_generator.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    directory=img_path,\n",
        "    x_col=\"id\",\n",
        "    y_col=\"usage\",\n",
        "    target_size=(96,96),\n",
        "    batch_size=batch_size,\n",
        "\n",
        "   \n",
        ")\n",
        "\n",
        "classes = len(training_generator.class_indices)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 35231 validated image filenames belonging to 5 classes.\n",
            "Found 8808 validated image filenames belonging to 5 classes.\n",
            "Found 4404 validated image filenames belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dd-p5LNhzuiH",
        "outputId": "59d09efd-333d-4578-d385-9c5a51232610"
      },
      "source": [
        "print(training_generator.class_indices)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Casual': 0, 'Ethnic': 1, 'Formal': 2, 'Smart Casual': 3, 'Sports': 4}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "waMwJT7_z1Wm",
        "outputId": "ce41f11f-ee52-46a0-acf4-4f76f35f49e2"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization,Dropout\n",
        "from keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32,(3,3), activation = 'relu', input_shape = (96,96,3)))\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "model.add(Conv2D(32,(3,3), activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32,(3,3), activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(classes, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), loss=tf.keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
        "model.summary()\n",
        "batch_size = 32\n",
        "total_train = train_df.shape[0]\n",
        "total_validation = validation_df.shape[0]\n",
        "vgg_classifier = model.fit(training_generator,\n",
        "steps_per_epoch=(total_train//batch_size),\n",
        "epochs = 10,\n",
        "validation_data=validation_generator,\n",
        "validation_steps=(total_validation//batch_size),\n",
        "batch_size = batch_size,\n",
        "verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 94, 94, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 47, 47, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 45, 45, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 22, 22, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 22, 22, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 20, 20, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 10, 10, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 10, 10, 32)        128       \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 3200)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 256)               819456    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 5)                 1285      \n",
            "=================================================================\n",
            "Total params: 840,389\n",
            "Trainable params: 840,261\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1100/1100 [==============================] - 248s 224ms/step - loss: 0.5725 - accuracy: 0.8080 - val_loss: 0.4555 - val_accuracy: 0.8459\n",
            "Epoch 2/10\n",
            "1100/1100 [==============================] - 246s 224ms/step - loss: 0.4445 - accuracy: 0.8470 - val_loss: 0.4957 - val_accuracy: 0.8420\n",
            "Epoch 3/10\n",
            "1100/1100 [==============================] - 246s 223ms/step - loss: 0.4213 - accuracy: 0.8539 - val_loss: 0.4081 - val_accuracy: 0.8609\n",
            "Epoch 4/10\n",
            "1100/1100 [==============================] - 247s 224ms/step - loss: 0.3985 - accuracy: 0.8647 - val_loss: 0.3825 - val_accuracy: 0.8620\n",
            "Epoch 5/10\n",
            "1100/1100 [==============================] - 247s 225ms/step - loss: 0.3780 - accuracy: 0.8695 - val_loss: 0.4726 - val_accuracy: 0.8325\n",
            "Epoch 6/10\n",
            "1100/1100 [==============================] - 247s 225ms/step - loss: 0.3540 - accuracy: 0.8747 - val_loss: 0.5132 - val_accuracy: 0.8411\n",
            "Epoch 7/10\n",
            "1100/1100 [==============================] - 249s 226ms/step - loss: 0.3494 - accuracy: 0.8773 - val_loss: 0.3805 - val_accuracy: 0.8782\n",
            "Epoch 8/10\n",
            "1100/1100 [==============================] - 249s 227ms/step - loss: 0.3414 - accuracy: 0.8817 - val_loss: 0.3917 - val_accuracy: 0.8616\n",
            "Epoch 9/10\n",
            "1100/1100 [==============================] - 250s 227ms/step - loss: 0.3296 - accuracy: 0.8837 - val_loss: 0.3770 - val_accuracy: 0.8768\n",
            "Epoch 10/10\n",
            "1100/1100 [==============================] - 248s 225ms/step - loss: 0.3263 - accuracy: 0.8856 - val_loss: 0.3531 - val_accuracy: 0.8900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ck9THMLK0B8h"
      },
      "source": [
        "model.save('modelForUsage.h5')\n",
        "result = model.evaluate(test_generator,batch_size=16)\n",
        "print(\"test_loss, test accuracy\",result)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}